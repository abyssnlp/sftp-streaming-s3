import os
import asyncio
from sftp_streaming.main import AsyncSFTPToS3Streamer


async def main():
    ssh_params = {
        "host": os.getenv("SFTP_HOST", "localhost"),
        "username": os.getenv("SFTP_USER", "airflow"),
        "password": os.getenv("SFTP_PASSWORD", "airflow123"),
        "port": int(os.getenv("SFTP_PORT", "30022")),
    }

    streamer = AsyncSFTPToS3Streamer(
        bucket_name=os.getenv("S3_BUCKET", "data"),
        push_gateway_url=os.getenv("PUSH_GATEWAY", "http://localhost:9091"),
        job_name="async-concurrent-file-transfer",
        ssh_connection_params=ssh_params,
        s3_endpoint_url="http://localhost:9000",
    )

    file_path = "/upload/customers_10gb.csv"

    print(f"ğŸš€ Starting HIGH-PERFORMANCE ASYNC CONCURRENT transfer of {file_path}")
    print("ğŸ’¡ Features enabled:")
    print("   â€¢ 4 concurrent async SFTP readers")
    print("   â€¢ 8 concurrent async S3 uploaders")
    print("   â€¢ Async connection pooling")
    print("   â€¢ Real-time performance monitoring")
    print("   â€¢ Expected significant speed improvement with asyncio!")
    print()
    print("ğŸ“Š Monitor real-time performance:")
    print("   â€¢ Prometheus metrics pushed every 2 seconds")
    print("   â€¢ Check updated Grafana dashboard for concurrency analytics")
    print("   â€¢ Watch for improved throughput with async operations!")

    try:
        await streamer.upload_to_s3(file_path)
        print("\nğŸ‰ ASYNC CONCURRENT TRANSFER COMPLETED SUCCESSFULLY! ğŸ‰")
        print("ğŸ“ˆ Check Grafana dashboard to see the async performance gains!")

    except Exception as e:
        print(f"âŒ Transfer failed: {e}")
        print(
            "ğŸ’¡ If you see SSH connection errors, ensure all SSH connection details are correct"
        )


if __name__ == "__main__":
    asyncio.run(main())
